# ğŸ“„ Retrieval-Augmented Generation (RAG) Document Question Answering System

## ğŸš€ Project Overview

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline that allows users to ask natural language questions over a collection of PDF documents and receive accurate, context-aware answers generated by a Large Language Model (LLM).

Instead of relying only on the LLMâ€™s internal knowledge, the system **retrieves relevant information from your own documents** and then generates responses grounded in that data. This approach is widely used in real-world AI applications such as chatbots, knowledge assistants, and enterprise search systems.

---

## ğŸ§  How It Works (High-Level Flow)

1. **Document Ingestion**
   PDF files are loaded, cleaned, and split into smaller text chunks.

2. **Vectorization**
   Each text chunk is converted into vector embeddings using an embedding model.

3. **Vector Storage**
   Embeddings are stored in a vector database for efficient similarity search.

4. **Retrieval + Generation**
   When a question is asked, the most relevant document chunks are retrieved and passed to an LLM to generate a final answer.

---

## ğŸ“ Project Structure

```
rag-document-qa/
â”‚
â”œâ”€â”€ docs_dir/                  # Sample PDF documents (knowledge source)
â”œâ”€â”€ 1_document_ingestion.ipynb # PDF loading, chunking, and embedding
â”œâ”€â”€ 2_vector_retrieval.ipynb   # Semantic search and question answering
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ .gitignore                 # Ignored files (env, vector DB, checkpoints)
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ LICENSE                    # MIT License
```

---

## ğŸ“š Documents (`docs_dir`)

* Contains **sample PDF files** used for demonstrating the RAG pipeline.
* Total content: **2 PDFs (~43 pages combined)**.
* These documents act as the private knowledge base for question answering.

> ğŸ“Œ You can replace these PDFs with your own documents to customize the system.

---

## ğŸ› ï¸ Technologies Used

* **Python**
* **LangChain** â€“ orchestration framework for LLM pipelines
* **ChromaDB** â€“ vector database for similarity search
* **Hugging Face Embeddings** â€“ text embedding generation
* **Groq LLM API** â€“ fast inference for question answering
* **Jupyter Notebook** â€“ experimentation and development

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/rag-document-qa.git
cd rag-document-qa
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
conda create -n rag-env python=3.10 -y
conda activate rag-env
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Environment Variables

Create a `.env` file in the project root:

```text
GROQ_API_KEY=your_api_key_here
```

> ğŸ”’ **Do not commit your `.env` file**

---

## â–¶ï¸ How to Run the Project

### Step 1: Document Ingestion

Open and run:

```
1_document_ingestion.ipynb
```

This notebook:

* Loads PDFs from `docs_dir/`
* Splits them into chunks
* Generates embeddings
* Stores them in a local vector database (not committed to GitHub)

### Step 2: Ask Questions

Open and run:

```
2_vector_retrieval.ipynb
```

This notebook:

* Retrieves relevant document chunks
* Sends context + question to the LLM
* Returns grounded, document-based answers

---

## ğŸ¯ Key Features

* âœ… Uses **your own documents** as knowledge
* âœ… Prevents hallucinations by grounding answers in retrieved data
* âœ… Modular pipeline (ingestion & retrieval separated)
* âœ… Easy to extend with new documents or models
* âœ… Industry-relevant RAG architecture

---

## ğŸ“Œ Use Cases

* Document-based chatbots
* Internal company knowledge assistants
* Research paper Q&A systems
* PDF search and summarization tools
* Enterprise AI applications

---

## ğŸ§© Future Improvements (Optional)

* Add a **Streamlit / Gradio UI**
* Support multiple document formats (DOCX, TXT)
* Add conversation memory
* Deploy as an API
* Experiment with hybrid search (BM25 + vectors)

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute.

---

## ğŸ™Œ Acknowledgements

* LangChain community
* Hugging Face
* ChromaDB
* Groq

---

â­ If you found this project helpful, consider giving it a star!
